{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Como o UniVAD Funciona: Uma Explica√ß√£o Detalhada\n",
        "\n",
        "Pense no UniVAD como um **detetive especialista** que nunca viu a \"cena do crime\" (a sua caixa de papel√£o) antes. Para descobrir se algo est√° errado em uma nova foto, ele s√≥ precisa de algumas fotos de refer√™ncia de como a cena \"normalmente\" se parece.\n",
        "\n",
        "Ele n√£o passa por um \"treinamento\" formal, mas usa sua vasta experi√™ncia (modelos pr√©-treinados) para fazer compara√ß√µes inteligentes. O trabalho desse detetive √© dividido em tr√™s m√≥dulos principais, que s√£o como tr√™s especialistas diferentes em sua equipe:\n",
        "\n",
        "#### **M√≥dulo 1: O Analista de Cena (Contextual Component Clustering - C¬≥)**\n",
        "\n",
        "Este √© o primeiro especialista a agir. Seu trabalho √© **identificar e isolar todos os objetos importantes** na imagem.\n",
        "*   **Ferramentas:** Ele usa dois modelos poderosos:\n",
        "    1.  **GroundingDINO:** Pense nele como o especialista em \"o qu√™\". Voc√™ d√° a ele uma descri√ß√£o em texto (ex: `\"cardboard box . packaging\"`) e ele encontra onde esses objetos est√£o na imagem, desenhando \"caixas\" (bounding boxes) ao redor deles.\n",
        "    2.  **Segment Anything Model (SAM):** Este √© o especialista em \"onde exatamente\". Ele pega as caixas desenhadas pelo GroundingDINO e cria uma m√°scara de segmenta√ß√£o pixel a pixel, um contorno perfeito para cada objeto detectado.\n",
        "*   **Resultado:** No final, este m√≥dulo entrega um conjunto de \"pe√ßas de quebra-cabe√ßa\" (m√°scaras), onde cada pe√ßa √© um componente da imagem (idealmente, a caixa inteira).\n",
        "\n",
        "#### **M√≥dulo 2: O Perito Forense (Component-Aware Patch Matching - CAPM)**\n",
        "\n",
        "Este especialista procura por **anomalias estruturais e de textura** ‚Äî defeitos f√≠sicos como arranh√µes, manchas, impress√£o errada, amassados, etc.\n",
        "*   **Como Funciona:** Ele usa a t√©cnica de \"correspond√™ncia de patches\":\n",
        "    1.  Pega cada \"pe√ßa do quebra-cabe√ßa\" (componente/m√°scara) da imagem de teste.\n",
        "    2.  Divide essa pe√ßa em milhares de pequenos \"quadrados\" (patches).\n",
        "    3.  Para cada patch, ele o compara com uma biblioteca gigante de patches \"normais\" que ele extraiu das imagens de refer√™ncia.\n",
        "*   **L√≥gica da Anomalia:** Se um patch da imagem de teste for muito diferente de **todos** os patches normais que ele j√° viu, ele √© considerado suspeito. A pontua√ß√£o de anomalia do patch √© a sua \"estranheza\" em rela√ß√£o √† normalidade.\n",
        "*   **Ferramentas:** Para fazer essa compara√ß√£o, ele n√£o compara os pixels diretamente. Ele usa \"olhos\" sofisticados para extrair a ess√™ncia de cada patch:\n",
        "    *   **CLIP (ViT-L):** Excelente em entender o **conte√∫do sem√¢ntico** (o \"significado\" do que est√° no patch).\n",
        "    *   **DINOv2 (ViT-G/L):** Excelente em entender a **estrutura fina, textura e geometria** do patch.\n",
        "*   **Resultado:** Um \"mapa de calor estrutural\" que destaca as √°reas da imagem com defeitos f√≠sicos.\n",
        "\n",
        "#### **M√≥dulo 3: O Detetive L√≥gico (Graph-Enhanced Component Modeling - GECM)**\n",
        "\n",
        "Este especialista procura por **anomalias l√≥gicas** ‚Äî erros de \"regras\" ou de montagem, como uma pe√ßa faltando, uma pe√ßa extra, ou uma pe√ßa no lugar errado.\n",
        "*   **Como Funciona:** Ele n√£o olha para os pequenos patches, mas para as \"pe√ßas do quebra-cabe√ßa\" inteiras.\n",
        "    1.  Ele analisa as caracter√≠sticas de cada pe√ßa: sua √°rea, cor m√©dia, posi√ß√£o na imagem e sua feature de \"deep learning\" (extra√≠da pelo CLIP/DINOv2).\n",
        "    2.  Ele modela as rela√ß√µes entre as pe√ßas em um \"grafo\". Por exemplo: \"a pe√ßa A (logo) est√° sempre em cima da pe√ßa B (aba da caixa)\".\n",
        "*   **L√≥gica da Anomalia:** Ele compara o conjunto de pe√ßas e suas rela√ß√µes na imagem de teste com o que ele aprendeu das imagens de refer√™ncia. Se a imagem de teste tem uma pe√ßa a mais, ou se a rela√ß√£o entre as pe√ßas est√° incorreta, ele atribui um score de anomalia l√≥gica.\n",
        "*   **Resultado:** Um \"mapa de calor l√≥gico\" que destaca componentes que est√£o ausentes, em excesso ou mal posicionados.\n",
        "\n",
        "#### **O Veredito Final (Agrega√ß√£o)**\n",
        "\n",
        "No final, o UniVAD combina os mapas de calor do Perito Forense (CAPM) e do Detetive L√≥gico (GECM) para criar um **mapa de anomalia final** e um **score de anomalia geral**, que nos diz o qu√£o \"anormal\" a imagem √© como um todo."
      ],
      "metadata": {
        "id": "4mxFYYhGnzK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 2. Resumo do Trabalho Realizado at√© Agora\n",
        "\n",
        "Esta √© uma lista detalhada e organizada de todo o progresso feito, que √© bastante significativo.\n",
        "\n",
        "**I. Coleta e Prepara√ß√£o do Dataset**\n",
        "*   **Cria√ß√£o de um Dataset Customizado:** Foram capturadas 554 imagens de alta variedade, cobrindo 43 caixas de papel√£o distintas (13 normais, 30 an√¥malas).\n",
        "*   **Variedade de Condi√ß√µes:** As imagens foram tiradas em m√∫ltiplos ambientes (ch√£o e esteira), com m√∫ltiplos √¢ngulos (3-4 por caixa) e utilizando duas c√¢meras de celular diferentes, garantindo robustez e realismo.\n",
        "*   **Coleta de V√≠deos:** Foram gravados v√≠deos do processo real em tr√™s m√°quinas distintas (cortadora, impressora, coladeira) para futura an√°lise ou expans√£o do dataset.\n",
        "*   **Organiza√ß√£o Estruturada:** O dataset foi organizado na estrutura de pastas `train/good`, `test/good` e `test/bad`, compat√≠vel com os frameworks de detec√ß√£o de anomalia.\n",
        "\n",
        "**II. Configura√ß√£o do Ambiente e Otimiza√ß√£o de Performance**\n",
        "*   **Resolu√ß√£o de Conflitos de Vers√£o:** Foram instaladas vers√µes espec√≠ficas das bibliotecas `transformers` e `tokenizers` para garantir a compatibilidade com o ambiente de execu√ß√£o (Python 3.12).\n",
        "*   **Gerenciamento de Mem√≥ria (VRAM):** O tamanho da imagem de entrada foi padronizado em `224x224` para permitir a execu√ß√£o dos modelos em GPUs com mem√≥ria limitada.\n",
        "*   **Redu√ß√£o de Modelos:** Para otimizar o uso de mem√≥ria, foram testadas vers√µes menores de modelos-chave:\n",
        "    *   O **Segment Anything Model** foi trocado da vers√£o `SAM-H` (Huge) para a `SAM-B` (Base).\n",
        "    *   O **DINOv2** foi trocado da vers√£o `ViT-G` (Giant) para a `ViT-L` (Large).\n",
        "*   **Carregamento Eficiente de Modelos:** O gargalo de performance de ~30s por imagem foi identificado e resolvido. A solu√ß√£o foi refatorar o `component_segmentation.py` para uma classe (`SegmentationHandler`) que carrega os modelos pesados (GroundingDINO, SAM) na VRAM uma √∫nica vez no in√≠cio, em vez de a cada imagem.\n",
        "\n",
        "**III. Refatora√ß√£o e Aprimoramento do Pipeline de Software**\n",
        "*   **Unifica√ß√£o do Fluxo de Trabalho:** O processo foi consolidado em um √∫nico script (`test_univad.py`), que realiza segmenta√ß√£o e infer√™ncia em sequ√™ncia para cada imagem. Isso simplificou drasticamente o processo de execu√ß√£o e depura√ß√£o.\n",
        "*   **Implementa√ß√£o de Par√¢metros de Teste:** O `test_univad.py` foi aprimorado com par√¢metros de linha de comando para permitir experimenta√ß√£o flex√≠vel:\n",
        "    *   `--debug`: Ativa o salvamento de mapas de calor e scores intermedi√°rios.\n",
        "    *   `--filter_with_mask`: Habilita a filtragem do score e do heatmap final usando a m√°scara de segmenta√ß√£o, focando a an√°lise apenas no objeto de interesse.\n",
        "    *   `--top_k_percent`: Substitui o c√°lculo de score baseado no `max()` por uma m√©dia dos `k%` pixels mais an√¥malos, tornando a pontua√ß√£o mais robusta.\n",
        "\n",
        "**IV. Otimiza√ß√£o da Segmenta√ß√£o e Detec√ß√£o**\n",
        "*   **Engenharia de Prompts:** Foram realizados testes e melhorias nos prompts de texto (`text_prompt` e `background_prompt`) no arquivo de configura√ß√£o do GroundingDINO para melhorar a precis√£o da segmenta√ß√£o, ensinando o modelo a focar na caixa e ignorar a esteira e o fundo.\n",
        "\n",
        "---\n",
        "No modo MULTI, que √© o √∫nico que utiliza o DinoFeaturizer, tinha que carregar esse modelo no init independente dele ser usado apenas no MULTI. Agora, tanto from modules import DinoFeaturizer quanto self.dino_net = DinoFeaturizer() s√£o realizados apenas no caso de ser MULTI.\n",
        "\n",
        "Limpeza da RAM logo ap√≥s carregar cada modelo na GPU"
      ],
      "metadata": {
        "id": "jK90Yxikn8Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "t0Ue9tD8qFyT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "3KvV3g9JqFtN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### Plano de A√ß√£o (TO-DO) Detalhado\n",
        "\n",
        "**FASE 1: Defini√ß√£o da Configura√ß√£o Base (Performance vs. Acur√°cia)**\n",
        "\n",
        "*O objetivo desta fase √© encontrar o melhor trade-off entre velocidade e acur√°cia, escolhendo a combina√ß√£o de modelos que ser√° usada em todos os testes seguintes.*\n",
        "\n",
        "*   **[ ] TO-DO 1.1: Avalia√ß√£o do Prompt de Segmenta√ß√£o**.\n",
        "    *   **Contexto:** O primeiro passo √© garantir que a segmenta√ß√£o seja a melhor poss√≠vel.\n",
        "    *   **Execu√ß√£o:**\n",
        "        1.  Execute o script com o **Prompt A** (ex: `\"cardboard box\"`).\n",
        "        2.  Execute o script com o **Prompt B** (ex: `\"cardboard box . packaging\"`).\n",
        "        3.  Execute o script com o **Prompt C** (ex: `\"the cardboard box on the conveyor\"`).\n",
        "    *   **An√°lise:** Inspecione visualmente as m√°scaras de segmenta√ß√£o geradas (arquivos `grounding_mask_color.png`). Conte o n√∫mero de \"falhas graves\" (ex: caixa n√£o detectada, detec√ß√£o grosseiramente errada) para cada prompt.\n",
        "    *   **Resultado:** Escolha o prompt que produzir o menor n√∫mero de segmenta√ß√µes ruidosas. **Este prompt ser√° usado para todos os testes subsequentes.**\n",
        "\n",
        "*   **[ ] TO-DO 1.2: Teste de Tempo de Infer√™ncia vs. Acur√°cia**.\n",
        "    *   **Contexto:** Usando o melhor prompt da etapa anterior, vamos testar diferentes \"motores\" para o UniVAD.\n",
        "    *   **Execu√ß√£o:** Execute o teste completo para cada uma das seguintes configura√ß√µes de modelo:\n",
        "        1.  **Config A (Leve):** SAM-B + DINOv2-L (Large)\n",
        "        2.  **Config B (Pesada):** SAM-H + DINOv2-L (Giant)\n",
        "        3.  **Config C (Qualidade M√°xima / Original):** SAM-H (Huge) + DINOv2-G (Giant)\n",
        "    *   **M√©tricas:** Para cada configura√ß√£o, registre:\n",
        "        *   **Tempo M√©dio por Imagem (s)**.\n",
        "        *   **Acur√°cia Geral Final (%)**.\n",
        "    *   **Resultado:** Crie uma tabela comparativa. A decis√£o aqui ser√° crucial: o ganho (se houver) de acur√°cia da Config B ou C justifica o tempo extra de processamento em rela√ß√£o √† Config A? A configura√ß√£o escolhida aqui ser√° a **configura√ß√£o base** para todas as fases seguintes.\n",
        "\n",
        "**FASE 2: Otimiza√ß√£o de Hiperpar√¢metros de Software**\n",
        "\n",
        "*O objetivo √© ajustar os par√¢metros do algoritmo usando a \"configura√ß√£o base\" definida na Fase 1.*\n",
        "\n",
        "*   **[ ] TO-DO 2.1: Testar o Impacto do `--top_k_percent`**.\n",
        "    *   **Execu√ß√£o:** Usando a configura√ß√£o base, rode o teste com diferentes valores: `0.0` (equivalente a Max), `0.01` (1%), `0.05` (5%) e `1.0` (equivalente a Mean).\n",
        "    *   **M√©trica:** Comparar a **Acur√°cia Geral (%)** para cada valor.\n",
        "    *   **An√°lise:** Determine qual m√©todo de agrega√ß√£o de score (Max, Top 1%, Top 5% ou Mean) produz a melhor acur√°cia. O valor vencedor ser√° usado nos testes de robustez.\n",
        "\n",
        "*   **[ ] TO-DO 2.2: Testar o Impacto do `--filter_with_mask`**.\n",
        "    *   **Execu√ß√£o:** Usando a configura√ß√£o base e o melhor `top_k_percent` encontrado, execute o teste duas vezes:\n",
        "        1.  **Sem** a flag `--filter_with_mask`.\n",
        "        2.  **Com** a flag `--filter_with_mask`.\n",
        "    *   **M√©trica:** Comparar a **Acur√°cia Geral (%)** entre as duas execu√ß√µes.\n",
        "    *   **Pergunta:** Focar a an√°lise de score apenas na √°rea da caixa segmentada melhora a performance da classifica√ß√£o?\n",
        "\n",
        "**FASE 3: Testes de Robustez e Sensibilidade do Modelo**\n",
        "\n",
        "*O objetivo √© estressar o modelo (com a melhor configura√ß√£o encontrada at√© agora) para entender seus limites e capacidades.*\n",
        "\n",
        "*   **[ ] TO-DO 3.1: Teste de `k-shot` (N√∫mero de Imagens de Refer√™ncia)**.\n",
        "    *   **Execu√ß√£o:**\n",
        "        1.  Rode com `--k_shot 1`.\n",
        "        2.  Rode com `--k_shot 4`, usando 4 imagens de refer√™ncia da mesma caixa \"boa\", mas de √¢ngulos diferentes.\n",
        "    *   **Pergunta:** Usar mais exemplos de refer√™ncia de diferentes perspectivas torna o modelo mais robusto?\n",
        "\n",
        "*   **[ ] TO-DO 3.2: Teste de Contexto da Refer√™ncia (Ch√£o vs. Esteira)**.\n",
        "    *   **Execu√ß√£o:**\n",
        "        1.  Rode o teste usando uma imagem de refer√™ncia de uma caixa no ch√£o.\n",
        "        2.  Rode o teste usando uma imagem de refer√™ncia de uma caixa na esteira.\n",
        "    *   **Pergunta:** O desempenho melhora quando o contexto da refer√™ncia (esteira) √© o mesmo do teste?\n",
        "\n",
        "*   **[ ] TO-DO 3.3: Teste de Qualidade da Imagem de Refer√™ncia**.\n",
        "    *   **Contexto:** Vamos avaliar o impacto de uma refer√™ncia \"ruim\" em um conjunto de teste \"ruim\".\n",
        "    *   **Execu√ß√£o:** Prepare um pequeno subconjunto de imagens de teste que estejam borradas.\n",
        "        1.  Execute o teste nesse subconjunto usando uma **refer√™ncia normal (n√≠tida)**.\n",
        "        2.  Execute o teste nesse subconjunto usando uma **refer√™ncia borrada**.\n",
        "    *   **Pergunta:** Usar uma refer√™ncia com o mesmo tipo de \"defeito\" (borr√£o) ajuda o modelo a ignor√°-lo e focar em anomalias reais?\n",
        "\n",
        "*   **[ ] TO-DO 3.4: Teste de Generaliza√ß√£o entre Caixas e C√¢meras**.\n",
        "    *   **Execu√ß√£o:**\n",
        "        1.  **Varia√ß√£o de Caixa:** Execute o teste usando a Caixa A (boa) como refer√™ncia. Anote a acur√°cia. Depois, execute novamente usando a Caixa B (boa, mas de outro modelo) como refer√™ncia. Anote a acur√°cia.\n",
        "        2.  **Varia√ß√£o de C√¢mera (Cross-Camera Test):**\n",
        "            *   Execute o teste usando uma imagem de refer√™ncia da **C√¢mera 1** e avalie a acur√°cia **apenas** no subconjunto de imagens da **C√¢mera 2**.\n",
        "            *   Execute o teste usando uma imagem de refer√™ncia da **C√¢mera 2** e avalie a acur√°cia **apenas** no subconjunto de imagens da **C√¢mera 1**.\n",
        "    *   **Pergunta:** O modelo √© sens√≠vel a pequenas mudan√ßas no modelo da caixa ou na c√¢mera usada, ou ele consegue generalizar bem?\n",
        "\n",
        "*   **[ ] TO-DO 3.5: Teste de Detec√ß√£o de √Çngulo**.\n",
        "    *   **An√°lise:** Ap√≥s rodar os testes, pegue uma caixa espec√≠fica que tenha um defeito claro e que foi fotografada de m√∫ltiplos √¢ngulos.\n",
        "    *   **Verifica√ß√£o:** Olhe os logs e os heatmaps salvos para essa caixa.\n",
        "    *   **Pergunta:** O modelo foi capaz de detectar o mesmo defeito consistentemente, independentemente do √¢ngulo da foto?"
      ],
      "metadata": {
        "id": "k24oIqd8lY_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A resposta para \"como come√ßar\" √©: **isolar o m√°ximo de vari√°veis poss√≠vel**.\n",
        "\n",
        "Comece estabelecendo uma **\"linha de base\" (baseline)** no cen√°rio mais simples e controlado. S√≥ depois de otimizar para *esse* cen√°rio √© que voc√™ come√ßa a introduzir as outras vari√°veis (c√¢mera 2, ch√£o, etc.) para testar a robustez.\n",
        "\n",
        "Aqui est√° a estrat√©gia de execu√ß√£o que eu recomendo, passo a passo, usando o seu pr√≥prio plano.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. üéØ O Ponto de Partida: Crie seu \"Grupo de Controle\"\n",
        "\n",
        "N√£o comece testando \"todas as imagens das duas c√¢meras\". Isso vai misturar muitas vari√°veis.\n",
        "\n",
        "**A√ß√£o:** Crie um \"Subconjunto de Teste Baseline\".\n",
        "1.  Escolha **apenas UMA c√¢mera** (ex: C√¢mera 1). Esque√ßa a C√¢mera 2 por enquanto.\n",
        "2.  Escolha **apenas UM contexto** que seja o mais representativo do seu objetivo final. Se o objetivo √© detectar na esteira, use a **Esteira**.\n",
        "    * **Imagens de Refer√™ncia (Train):** Pegue suas `k` imagens \"boas\" da **C√¢mera 1** na **Esteira**.\n",
        "    * **Imagens de Teste (Test):** Use *todas* as imagens (boas e ruins) da **C√¢mera 1** na **Esteira**.\n",
        "\n",
        "Este `C√¢mera 1 + Esteira` √© seu **Grupo de Controle**. Agora, vamos otimizar os par√¢metros *apenas* para ele.\n",
        "\n",
        "---\n",
        "\n",
        "### 2. ‚öôÔ∏è Execute a FASE 1 (Definindo a Configura√ß√£o Base)\n",
        "\n",
        "Use *apenas* o seu Grupo de Controle para todos os testes desta fase.\n",
        "\n",
        "1.  **[TO-DO 1.1: Avalia√ß√£o do Prompt]:**\n",
        "    * Use o Grupo de Controle (C√¢mera 1/Esteira).\n",
        "    * Teste os Prompts A, B e C.\n",
        "    * **Decis√£o:** Escolha o prompt que der as melhores m√°scaras de segmenta√ß√£o. Este √© seu **Prompt Vencedor**.\n",
        "\n",
        "2.  **[TO-DO 1.2: Teste de Tempo vs. Acur√°cia]:**\n",
        "    * Use o Grupo de Controle (C√¢mera 1/Esteira) e o **Prompt Vencedor**.\n",
        "    * Teste as Configs A (Leve), B (Pesada) e C (Original).\n",
        "    * **Decis√£o:** Crie sua tabela de Tempo vs. Acur√°cia. Escolha a melhor rela√ß√£o custo-benef√≠cio (ex: Config A). Esta √© sua **Configura√ß√£o Base**.\n",
        "\n",
        "**Resultado da Fase 1:** Voc√™ ter√° a `Configura√ß√£o Base` (ex: Config A + Prompt B).\n",
        "\n",
        "---\n",
        "\n",
        "### 3. üî¨ Execute a FASE 2 (Otimiza√ß√£o de Hiperpar√¢metros)\n",
        "\n",
        "Continue usando *apenas* o seu Grupo de Controle (C√¢mera 1/Esteira) e a `Configura√ß√£o Base` que voc√™ acabou de encontrar.\n",
        "\n",
        "1.  **[TO-DO 2.1: Teste do `--top_k_percent`]:**\n",
        "    * Teste os diferentes valores (0.0, 0.01, 0.05, 1.0).\n",
        "    * **Decis√£o:** Escolha o valor que der a maior Acur√°cia Geral. Este √© seu **Par√¢metro Top_K Vencedor**.\n",
        "\n",
        "2.  **[TO-DO 2.2: Teste do `--filter_with_mask`]:**\n",
        "    * Use o seu **Par√¢metro Top_K Vencedor**.\n",
        "    * Teste com e sem a flag `--filter_with_mask`.\n",
        "    * **Decis√£o:** Escolha a op√ß√£o que der a maior Acur√°cia Geral.\n",
        "\n",
        "**Resultado da Fase 2:** Voc√™ agora tem sua **Configura√ß√£o Otimizada Final** (ex: Config A + Prompt B + Top_K 5% + Com Filtro).\n",
        "\n",
        "---\n",
        "\n",
        "### 4. üåç Execute a FASE 3 (Testes de Robustez)\n",
        "\n",
        "**Agora sim** √© a hora de introduzir as vari√°veis que voc√™ estava se perguntando (ch√£o, C√¢mera 2). Use a sua **Configura√ß√£o Otimizada Final** para *todos* os testes desta fase.\n",
        "\n",
        "O objetivo aqui n√£o √© mais \"achar a melhor config\", mas sim \"ver o qu√£o bem a minha melhor config se comporta em cen√°rios dif√≠ceis\".\n",
        "\n",
        "1.  **[TO-DO 3.2: Teste de Contexto (Ch√£o vs. Esteira)]:**\n",
        "    * Use a Config Otimizada.\n",
        "    * **Teste 1 (Baseline):** Ref (Esteira) -> Teste (Esteira). Anote a Acur√°cia (voc√™ j√° tem esse n√∫mero da Fase 2).\n",
        "    * **Teste 2 (Robustez):** Ref (**Ch√£o**) -> Teste (Esteira). Anote a Acur√°cia.\n",
        "    * **An√°lise:** Compare a Acur√°cia do Teste 1 vs. Teste 2. Isso lhe dir√° o qu√£o sens√≠vel o modelo √© ao contexto do fundo.\n",
        "\n",
        "2.  **[TO-DO 3.4: Teste de Generaliza√ß√£o (Cross-Camera)]:**\n",
        "    * Use a Config Otimizada.\n",
        "    * **Teste 1 (Baseline C1):** Ref (C√¢mera 1) -> Teste (C√¢mera 1). Anote Acur√°cia.\n",
        "    * **Teste 2 (Baseline C2):** Ref (C√¢mera 2) -> Teste (C√¢mera 2). Anote Acur√°cia.\n",
        "    * **Teste 3 (Cross-C√¢mera A):** Ref (C√¢mera 1) -> Teste (C√¢mera 2). Anote Acur√°cia.\n",
        "    * **Teste 4 (Cross-C√¢mera B):** Ref (C√¢mera 2) -> Teste (C√¢mera 1). Anote Acur√°cia.\n",
        "    * **An√°lise:** Compare os resultados. Se a acur√°cia do Teste 3 e 4 for muito menor que a do 1 e 2, seu modelo √© muito sens√≠vel √† c√¢mera e talvez voc√™ precise de imagens de refer√™ncia de ambas as c√¢meras.\n",
        "\n",
        "3.  Execute os outros testes da Fase 3 (`k-shot`, qualidade, √¢ngulo) da mesma forma, sempre usando sua **Configura√ß√£o Otimizada Final** como ponto de partida e mudando **apenas uma vari√°vel por vez**."
      ],
      "metadata": {
        "id": "ZZYTu3VsJtk0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fase 1.1: Avalia√ß√£o do Prompt (Teste A)\n",
        "\n",
        "* **Par√¢metros:** Grupo de Controle (C√¢mera 1 / Esteira) com prompt `\"cardboard box . box\"`.\n",
        "* **Resultados:** 46 segmenta√ß√µes problem√°ticas em 125 caixas (Taxa de Erro: 36.8%).\n",
        "* **An√°lise de Erro:** Os erros dividem-se em 21 identifica√ß√µes de caixas ao fundo e 25 outras falhas de segmenta√ß√£o.\n",
        "\n",
        "### Fase 1.1: Avalia√ß√£o do Prompt (Teste B)\n",
        "\n",
        "* **Par√¢metros:** Grupo de Controle (C√¢mera 1 / Esteira) com prompt `\"a single cardboard box in the foreground on top of a conveyor belt\"`.\n",
        "* **Resultados:** 24 segmenta√ß√µes problem√°ticas em 125 caixas (Taxa de Erro: 19.2%).\n",
        "* **An√°lise de Erro:** Os erros dividem-se em 5 identifica√ß√µes de caixas ao fundo e 19 outras falhas de segmenta√ß√£o.\n",
        "\n",
        "### Fase 1.1: Avalia√ß√£o do Prompt (Testes C e D - Ajuste de Threshold)\n",
        "\n",
        "* **Par√¢metros:** Prompt do Teste B (`\"a single cardboard box...\"`) com `box_threshold` e `text_threshold` ajustados.\n",
        "    * **Teste C:** Thresholds = 0.35\n",
        "    * **Teste D:** Thresholds = 0.45\n",
        "* **Resultados (Id√™nticos para C e D):** 19 segmenta√ß√µes problem√°ticas em 125 caixas (Taxa de Erro: 15.2%).\n",
        "* **An√°lise de Erro (Id√™ntica para C e D):** Os erros dividem-se em 4 identifica√ß√µes de caixas ao fundo e 15 outras falhas de segmenta√ß√£o.\n",
        "\n",
        "### Fase 1.1: Avalia√ß√£o do Prompt (Teste E)\n",
        "\n",
        "* **Par√¢metros:** Grupo de Controle (C√¢mera 1 / Esteira), prompt `\"a flat cardboard box with text printed on it\"`, thresholds = 0.35.\n",
        "* **Resultados:** 8 segmenta√ß√µes problem√°ticas em 125 caixas (Taxa de Erro: 6.4%).\n",
        "* **An√°lise de Erro:**\n",
        "    * Erros de caixas ao fundo: 0\n",
        "    * Segmenta√ß√£o da esteira: 2\n",
        "    * Segmenta√ß√£o parcial da caixa: 6"
      ],
      "metadata": {
        "id": "ZKAKZ7V407A3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fase 1.2: Teste de Tempo vs. Acur√°cia (Config B)\n",
        "\n",
        "* **Configura√ß√£o:** Config B (Pesada): SAM-H + DINOv2-L (Giant).\n",
        "* **Resultados (Performance):** Acur√°cia = 85.60%, AUC = 0.95.\n",
        "* **Resultados (Tempo):**\n",
        "    * T_Seg (M√©dio): 3.3154 s\n",
        "    * T_Pred (M√©dio): 0.2918 s\n",
        "    * T_Total (M√©dio): 3.6072 s\n",
        "\n",
        "### Fase 1.2: Teste de Tempo vs. Acur√°cia (Config A)\n",
        "\n",
        "* **Configura√ß√£o:** SAM-B + Dinov2-l.\n",
        "* **Resultados (Performance):** Acur√°cia = 85.60%, AUC = 0.9549.\n",
        "* **Resultados (Tempo):**\n",
        "    * T_Seg (M√©dio): 1.6242 s\n",
        "    * T_Pred (M√©dio): 0.2906 s\n",
        "    * T_Total (M√©dio): 1.9147 s"
      ],
      "metadata": {
        "id": "EILp2q4YL35U"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqFRodBxk6Gm"
      },
      "source": [
        "### Links de Refer√™ncia para o UniVAD\n",
        "* **Reposit√≥rio no GitHub:** [https://github.com/FantasticGNU/UniVAD](https://github.com/FantasticGNU/UniVAD)\n",
        "* **Artigo (Paper):** [https://arxiv.org/pdf/2412.03342](https://arxiv.org/pdf/2412.03342)\n",
        "* **Site do Projeto:** [https://uni-vad.github.io/](https://uni-vad.github.io/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --recurse-submodules https://github.com/MateusPereiraAlves/UniVAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8h0s7p1LCFf",
        "outputId": "cf6150b3-b27e-452b-a888-b94ce6e4acb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UniVAD'...\n",
            "remote: Enumerating objects: 557, done.\u001b[K\n",
            "remote: Counting objects: 100% (557/557), done.\u001b[K\n",
            "remote: Compressing objects: 100% (407/407), done.\u001b[K\n",
            "remote: Total 557 (delta 166), reused 500 (delta 130), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (557/557), 7.91 MiB | 20.97 MiB/s, done.\n",
            "Resolving deltas: 100% (166/166), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG5LVKd3yWzX",
        "outputId": "c095a38a-5194-4d60-d030-2de7787c6479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UniVAD\n"
          ]
        }
      ],
      "source": [
        "%cd UniVAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M2wf5mt_yNVh",
        "outputId": "830c7801-616d-4694-e98c-339e72cabdce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydensecrf@ git+https://github.com/lucasb-eyer/pydensecrf.git (from -r requirements.txt (line 18))\n",
            "  Cloning https://github.com/lucasb-eyer/pydensecrf.git to /tmp/pip-install-xk7o7uw3/pydensecrf_958563c55f0a422296a9610cab1f9fae\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lucasb-eyer/pydensecrf.git /tmp/pip-install-xk7o7uw3/pydensecrf_958563c55f0a422296a9610cab1f9fae\n",
            "  Resolved https://github.com/lucasb-eyer/pydensecrf.git to commit 2723c7fa4f2ead16ae1ce3d8afe977724bb8f87f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ram@ git+https://github.com/xinyu1205/recognize-anything.git (from -r requirements.txt (line 37))\n",
            "  Cloning https://github.com/xinyu1205/recognize-anything.git to /tmp/pip-install-xk7o7uw3/ram_c7d3307248ce4f4aa8e6a03982015c7b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/xinyu1205/recognize-anything.git /tmp/pip-install-xk7o7uw3/ram_c7d3307248ce4f4aa8e6a03982015c7b\n",
            "  Resolved https://github.com/xinyu1205/recognize-anything.git to commit 7cb804a8609e9f4b1a50b7f31436d2df40bb9481\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting segment_anything@ git+https://github.com/facebookresearch/segment-anything.git (from -r requirements.txt (line 38))\n",
            "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-install-xk7o7uw3/segment-anything_864a76754a9b4a3d97099bb0cd78157c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-install-xk7o7uw3/segment-anything_864a76754a9b4a3d97099bb0cd78157c\n",
            "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from -r requirements.txt (line 1))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting clip (from -r requirements.txt (line 2))\n",
            "  Downloading clip-0.2.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.8.1)\n",
            "Collecting fairscale (from -r requirements.txt (line 4))\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fiftyone (from -r requirements.txt (line 5))\n",
            "  Downloading fiftyone-1.10.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting ftfy (from -r requirements.txt (line 6))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting gradio==4.21.0 (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-4.21.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.36.0)\n",
            "Collecting ipdb (from -r requirements.txt (line 9))\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting kornia (from -r requirements.txt (line 10))\n",
            "  Downloading kornia-0.8.2-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (2.0.2)\n",
            "Requirement already satisfied: opencv_python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (4.12.0.88)\n",
            "Requirement already satisfied: opencv_python_headless in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (11.3.0)\n",
            "Collecting pycocoevalcap (from -r requirements.txt (line 16))\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.0.10)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 20)) (2024.11.6)\n",
            "Requirement already satisfied: Requests in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 21)) (2.32.4)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 22)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 23)) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (75.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 25)) (0.25.2)\n",
            "Collecting supervision (from -r requirements.txt (line 26))\n",
            "  Downloading supervision-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 27)) (3.2.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 28)) (1.0.21)\n",
            "Collecting torch==2.2.0 (from -r requirements.txt (line 29))\n",
            "  Downloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchmetrics (from -r requirements.txt (line 30))\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 31)) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 32)) (4.67.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 33)) (4.57.1)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 34)) (0.20.0)\n",
            "Collecting wget (from -r requirements.txt (line 35))\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting yapf (from -r requirements.txt (line 36))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting segment-anything-hq (from -r requirements.txt (line 39))\n",
            "  Downloading segment_anything_hq-0.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting prefetch_generator (from -r requirements.txt (line 40))\n",
            "  Downloading prefetch_generator-1.0.3.tar.gz (4.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==4.21.0->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (5.5.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.121.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.6.4)\n",
            "Collecting gradio-client==0.12.0 (from gradio==4.21.0->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-0.12.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==4.21.0->-r requirements.txt (line 7))\n",
            "  Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting numpy (from -r requirements.txt (line 12))\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (3.11.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (2.2.2)\n",
            "Collecting Pillow (from -r requirements.txt (line 15))\n",
            "  Downloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (2.11.10)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.14.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (2.10.0)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.21.0->-r requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (4.15.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio==4.21.0->-r requirements.txt (line 7)) (0.38.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->-r requirements.txt (line 29)) (3.20.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->-r requirements.txt (line 29)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->-r requirements.txt (line 29)) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.2.0->-r requirements.txt (line 29)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch==2.2.0->-r requirements.txt (line 29))\n",
            "  Downloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.12.0->gradio==4.21.0->-r requirements.txt (line 7))\n",
            "  Downloading websockets-11.0.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->-r requirements.txt (line 29)) (12.6.85)\n",
            "Collecting argcomplete (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting async_lru>=2 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (4.13.5)\n",
            "Collecting boto3 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading boto3-1.40.69-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (5.5.2)\n",
            "Collecting dacite<2,>=1.6.0 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading dacite-1.9.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (0.3.8)\n",
            "Collecting Deprecated (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading deprecated-1.3.1-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (4.14.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading hypercorn-0.18.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jsonpatch in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (1.33)\n",
            "Collecting mongoengine~=0.29.1 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading mongoengine-0.29.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting motor~=3.6.0 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading motor-3.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting plotly>=6.1.1 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pprintpp (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (5.9.5)\n",
            "Collecting pymongo~=4.9.2 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pymongo-4.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (2025.2)\n",
            "Collecting retrying (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting rtree (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: starlette>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (0.49.3)\n",
            "Collecting strawberry-graphql>=0.262.4 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading strawberry_graphql-0.284.2-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fiftyone->-r requirements.txt (line 5)) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading xmltodict-1.0.2-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pydash (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting fiftyone-brain<0.22,>=0.21.3 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading fiftyone_brain-0.21.4-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting fiftyone-db<2.0,>=0.4 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading fiftyone_db-1.4.0.tar.gz (8.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.16,>=0.15.1 (from fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading voxel51_eta-0.15.1-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->-r requirements.txt (line 6)) (0.2.14)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->-r requirements.txt (line 8)) (1.2.0)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.12/dist-packages (from ipdb->-r requirements.txt (line 9)) (7.34.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipdb->-r requirements.txt (line 9)) (4.4.2)\n",
            "Collecting kornia_rs>=0.1.9 (from kornia->-r requirements.txt (line 10))\n",
            "  Downloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv_python (from -r requirements.txt (line 13))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "INFO: pip is looking at multiple versions of opencv-python-headless to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv_python_headless (from -r requirements.txt (line 14))\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from Requests->-r requirements.txt (line 21)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from Requests->-r requirements.txt (line 21)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from Requests->-r requirements.txt (line 21)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from Requests->-r requirements.txt (line 21)) (2025.10.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn->-r requirements.txt (line 22)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit_learn->-r requirements.txt (line 22)) (3.6.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 25)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 25)) (2025.10.16)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 25)) (0.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->-r requirements.txt (line 26)) (0.7.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 28)) (0.6.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->-r requirements.txt (line 30))\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from -r requirements.txt (line 31))\n",
            "  Downloading torchvision-0.24.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
            "  Downloading torchvision-0.23.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.21.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.20.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "INFO: pip is still looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torchvision-0.19.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "  Downloading torchvision-0.18.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.2-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading torchvision-0.17.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "  Downloading torchvision-0.17.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 33)) (0.22.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->-r requirements.txt (line 34)) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer->-r requirements.txt (line 34)) (13.9.4)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/dist-packages (from yapf->-r requirements.txt (line 36)) (4.5.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (2.10.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio==4.21.0->-r requirements.txt (line 7)) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.24.1->gradio==4.21.0->-r requirements.txt (line 7)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.21.0->-r requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: h2>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from hypercorn>=0.13.2->fiftyone->-r requirements.txt (line 5)) (4.3.0)\n",
            "Collecting priority (from hypercorn>=0.13.2->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (0.2.1)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (4.9.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio==4.21.0->-r requirements.txt (line 7)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.21.0->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.21.0->-r requirements.txt (line 7)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->gradio==4.21.0->-r requirements.txt (line 7)) (0.4.2)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo~=4.9.2->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer->-r requirements.txt (line 34)) (4.0.0)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql>=0.262.4->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting lia-web>=0.2.1 (from strawberry-graphql>=0.262.4->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading lia_web-0.2.3-py3-none-any.whl.metadata (1.1 kB)\n",
            "\u001b[33mWARNING: typer 0.20.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: glob2 in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting paramiko<4,>=3 (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading paramiko-3.5.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting rarfile (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (2.4.0)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (5.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->fiftyone->-r requirements.txt (line 5)) (2.8)\n",
            "Collecting botocore<1.41.0,>=1.40.69 (from boto3->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading botocore-1.40.69-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<3,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->fiftyone->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi->gradio==4.21.0->-r requirements.txt (line 7)) (0.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch->fiftyone->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.2.0->-r requirements.txt (line 29)) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.24.1->gradio==4.21.0->-r requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone->-r requirements.txt (line 5)) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2>=4.3.0->hypercorn>=0.13.2->fiftyone->-r requirements.txt (line 5)) (4.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (0.8.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.21.0->-r requirements.txt (line 7)) (0.28.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->-r requirements.txt (line 34)) (0.1.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.12/dist-packages (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (43.0.3)\n",
            "Collecting pynacl>=1.5 (from paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb->-r requirements.txt (line 9)) (0.7.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: pycryptodomex>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (3.23.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (1.1.0)\n",
            "Collecting pyzstd>=0.16.1 (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading pybcj-1.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5))\n",
            "  Downloading inflate64-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko<4,>=3->voxel51-eta<0.16,>=0.15.1->fiftyone->-r requirements.txt (line 5)) (2.23)\n",
            "Downloading gradio-4.21.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.0-cp312-cp312-manylinux1_x86_64.whl (755.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m755.4/755.4 MB\u001b[0m \u001b[31m807.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m135.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m114.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading triton-2.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading fiftyone-1.10.0-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Downloading kornia-0.8.2-py2.py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading supervision-0.26.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.0-cp312-cp312-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m122.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segment_anything_hq-0.3-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
            "Downloading dacite-1.9.2-py3-none-any.whl (16 kB)\n",
            "Downloading fiftyone_brain-0.21.4-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.6/112.6 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hypercorn-0.18.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading mongoengine-0.29.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.6.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading strawberry_graphql-0.284.2-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m307.1/307.1 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Downloading voxel51_eta-0.15.1-py2.py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.69-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecated-1.3.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-1.0.2-py3-none-any.whl (13 kB)\n",
            "Downloading botocore-1.40.69-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lia_web-0.2.3-py3-none-any.whl (13 kB)\n",
            "Downloading paramiko-3.5.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m118.1/118.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m69.7/69.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m97.0/97.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynacl-1.6.0-cp38-abi3-manylinux_2_34_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.18.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (429 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m429.9/429.9 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: clip, fairscale, pydensecrf, wget, ram, segment_anything, prefetch_generator, fiftyone-db\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=4b5daef765869cefb54dc25538694422a0181f8a94fb3dfd5673356a30ebbbf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/fd/54/9d4e15cf829b871199a7cd3597e869a514d1624a0a43076896\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=c83281336cf05a9fef970962aaadc5789ce7b322b4dc758da5cfc2090e874514\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/88/aa/d84b2cf1bad6b273cbf661640141a82c7b9f496e024f80aac0\n",
            "  Building wheel for pydensecrf (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pydensecrf: filename=pydensecrf-1.0-cp312-cp312-linux_x86_64.whl size=3494608 sha256=be3ca9670572d71f8a1320d3cfbc30200ca51d88aff70d3be6efe566f43c532b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b8turecb/wheels/5f/63/9b/ad8357747651277615ec2094c768471e8ecde7d7b53564f24d\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=6f937d46ff32a95fbad43bde6b0c3d37cea9e3f4c14a16ba274167a41de5536c\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "  Building wheel for ram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ram: filename=ram-0.0.1-py3-none-any.whl size=128837 sha256=5e4fc36ea512d5ac44a86cc1ece14aa8ffcf11d82df01ecdaee5692de5a4129c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b8turecb/wheels/fb/22/8f/65b4960e80f59a09828812e50c1112198fe699fa986af87522\n",
            "  Building wheel for segment_anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segment_anything: filename=segment_anything-1.0-py3-none-any.whl size=36592 sha256=83f3ae46083c8660fc921ffd3b804fe062541100f31486e663e575797174dd1d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b8turecb/wheels/29/82/ff/04e2be9805a1cb48bec0b85b5a6da6b63f647645750a0e42d4\n",
            "  Building wheel for prefetch_generator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prefetch_generator: filename=prefetch_generator-1.0.3-py3-none-any.whl size=4758 sha256=93c50befd28053d68cdd7eb80f457c1a240f81672d2d326d4b94145ff78e4adb\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/88/c7/3b5afc342fc80a599ce41ba9000cf8a71261991c35cf088edf\n",
            "  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.4.0-py3-none-manylinux1_x86_64.whl size=50602142 sha256=77b442b4de2cce6686109812f316af78be538ddd2fa0676c1aa33d1796e3f714\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/0f/f5/2369e7d61abb1150548234c50c71f01f524874f8dabbe6ce88\n",
            "Successfully built clip fairscale pydensecrf wget ram segment_anything prefetch_generator fiftyone-db\n",
            "Installing collected packages: wget, texttable, sseclient-py, segment_anything, ram, pydensecrf, prefetch_generator, pprintpp, clip, addict, yapf, xmltodict, wsproto, websockets, triton, tomlkit, rtree, retrying, rarfile, pyzstd, pyppmd, pydash, pybcj, priority, plotly, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, multivolumefile, markupsafe, lightning-utilities, lia-web, kornia_rs, jsonlines, jmespath, jedi, inflate64, graphql-core, ftfy, fiftyone-db, dnspython, Deprecated, dacite, bcrypt, async_lru, argcomplete, aiofiles, strawberry-graphql, pynacl, pymongo, py7zr, opencv_python_headless, opencv_python, nvidia-cusolver-cu12, nvidia-cudnn-cu12, hypercorn, botocore, universal-analytics-python3, torch, sse-starlette, s3transfer, pycocoevalcap, paramiko, motor, mongoengine, ipdb, gradio-client, voxel51-eta, torchvision, torchmetrics, supervision, kornia, fiftyone-brain, fairscale, boto3, segment-anything-hq, gradio, fiftyone\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.3\n",
            "    Uninstalling tomlkit-0.13.3:\n",
            "      Successfully uninstalled tomlkit-0.13.3\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.3\n",
            "    Uninstalling MarkupSafe-3.0.3:\n",
            "      Successfully uninstalled MarkupSafe-3.0.3\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: opencv_python_headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: opencv_python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: sse-starlette\n",
            "    Found existing installation: sse-starlette 3.0.3\n",
            "    Uninstalling sse-starlette-3.0.3:\n",
            "      Successfully uninstalled sse-starlette-3.0.3\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.13.3\n",
            "    Uninstalling gradio_client-1.13.3:\n",
            "      Successfully uninstalled gradio_client-1.13.3\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.49.1\n",
            "    Uninstalling gradio-5.49.1:\n",
            "      Successfully uninstalled gradio-5.49.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.17.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 11.0.3 which is incompatible.\n",
            "mcp 1.20.0 requires sse-starlette>=1.6.1, but you have sse-starlette 0.10.3 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 11.0.3 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.2.0 which is incompatible.\n",
            "google-genai 1.48.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 11.0.3 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 11.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.3.1 Pillow-10.4.0 addict-2.4.0 aiofiles-23.2.1 argcomplete-3.6.3 async_lru-2.0.5 bcrypt-5.0.0 boto3-1.40.69 botocore-1.40.69 clip-0.2.0 dacite-1.9.2 dnspython-2.8.0 fairscale-0.4.13 fiftyone-1.10.0 fiftyone-brain-0.21.4 fiftyone-db-1.4.0 ftfy-6.3.1 gradio-4.21.0 gradio-client-0.12.0 graphql-core-3.2.7 hypercorn-0.18.0 inflate64-1.0.3 ipdb-0.13.13 jedi-0.19.2 jmespath-1.0.1 jsonlines-4.0.0 kornia-0.8.2 kornia_rs-0.1.10 lia-web-0.2.3 lightning-utilities-0.15.2 markupsafe-2.1.5 mongoengine-0.29.1 motor-3.6.1 multivolumefile-0.2.3 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 opencv_python-4.11.0.86 opencv_python_headless-4.11.0.86 paramiko-3.5.1 plotly-6.4.0 pprintpp-0.4.0 prefetch_generator-1.0.3 priority-2.0.0 py7zr-1.0.0 pybcj-1.0.6 pycocoevalcap-1.2 pydash-8.0.5 pydensecrf-1.0 pymongo-4.9.2 pynacl-1.6.0 pyppmd-1.2.0 pyzstd-0.18.0 ram-0.0.1 rarfile-4.2 retrying-1.4.2 rtree-1.4.1 s3transfer-0.14.0 segment-anything-hq-0.3 segment_anything-1.0 sse-starlette-0.10.3 sseclient-py-1.8.0 strawberry-graphql-0.284.2 supervision-0.26.1 texttable-1.7.0 tomlkit-0.12.0 torch-2.2.0 torchmetrics-1.8.2 torchvision-0.17.0 triton-2.2.0 universal-analytics-python3-1.1.1 voxel51-eta-0.15.1 websockets-11.0.3 wget-3.2 wsproto-1.2.0 xmltodict-1.0.2 yapf-0.43.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "8caef43629924950b26ef39df180d869"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H67k7kkyZhQ",
        "outputId": "bd115854-9889-4856-b499-9f3b9bf90b5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UniVAD/models/GroundingDINO\n",
            "Obtaining file:///content/UniVAD/models/GroundingDINO\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (4.57.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.4.0)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.43.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (1.0.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (4.11.0.86)\n",
            "Requirement already satisfied: supervision in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (0.26.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from groundingdino==0.1.0) (2.0.10)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (1.16.3)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (3.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (6.0.3)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (0.7.1)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (10.4.0)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.12/dist-packages (from supervision->groundingdino==0.1.0) (4.67.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm->groundingdino==0.1.0) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm->groundingdino==0.1.0) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.12/dist-packages (from torch->groundingdino==0.1.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->groundingdino==0.1.0) (12.6.85)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (25.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->groundingdino==0.1.0) (0.22.1)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.12/dist-packages (from yapf->groundingdino==0.1.0) (4.5.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm->groundingdino==0.1.0) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->groundingdino==0.1.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->groundingdino==0.1.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->groundingdino==0.1.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision->groundingdino==0.1.0) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->groundingdino==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->groundingdino==0.1.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision->groundingdino==0.1.0) (1.17.0)\n",
            "Installing collected packages: groundingdino\n",
            "  Running setup.py develop for groundingdino\n",
            "Successfully installed groundingdino-0.1.0\n"
          ]
        }
      ],
      "source": [
        "%cd models/GroundingDINO\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Baixar Modelos e Configurar Scripts (Vers√£o Corrigida 3)\n",
        "#@markdown Defina a vers√£o do SAM. O script ir√° baixar o modelo\n",
        "#@markdown e modificar o arquivo `.py` automaticamente.\n",
        "SAM_VERSION = \"SAM-B\" #@param [\"SAM-H\", \"SAM-L\", \"SAM-B\"]\n",
        "\n",
        "import os\n",
        "\n",
        "# --- 1. Definir Caminhos e Vari√°veis ---\n",
        "CKPT_DIR = \"/content/UniVAD/pretrained_ckpts\"\n",
        "CONFIG_FILE = \"/content/UniVAD/models/component_segmentaion.py\"\n",
        "DINO_FILENAME = \"groundingdino_swint_ogc.pth\"\n",
        "DINO_URL = \"https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\"\n",
        "\n",
        "# Garante que o diret√≥rio de checkpoints exista\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "# Muda o diret√≥rio atual para l√° (para os downloads)\n",
        "%cd {CKPT_DIR}\n",
        "\n",
        "# Define os par√¢metros com base na sele√ß√£o\n",
        "if SAM_VERSION == \"SAM-H\":\n",
        "  CKPT_FILENAME = \"sam_hq_vit_h.pth\"\n",
        "  MODEL_KEY = \"h\"\n",
        "  SAM_URL = \"https://huggingface.co/lkeab/hq-sam/resolve/main/sam_hq_vit_h.pth\"\n",
        "elif SAM_VERSION == \"SAM-L\":\n",
        "  CKPT_FILENAME = \"sam_vit_l.pth\"\n",
        "  MODEL_KEY = \"l\"\n",
        "  SAM_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth\"\n",
        "elif SAM_VERSION == \"SAM-B\":\n",
        "  CKPT_FILENAME = \"sam_vit_b.pth\"\n",
        "  MODEL_KEY = \"b\"\n",
        "  SAM_URL = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
        "else:\n",
        "  CKPT_FILENAME = None\n",
        "  print(\"Modelo SAM n√£o dispon√≠vel.\")\n",
        "\n",
        "# --- 2. Baixar os Modelos (se necess√°rio) ---\n",
        "\n",
        "# Baixa o SAM\n",
        "if CKPT_FILENAME and not os.path.exists(CKPT_FILENAME):\n",
        "  print(f\"Baixando {CKPT_FILENAME}...\")\n",
        "  !wget {SAM_URL} -O {CKPT_FILENAME}\n",
        "elif CKPT_FILENAME:\n",
        "  print(f\"{CKPT_FILENAME} j√° existe. Pulando download.\")\n",
        "\n",
        "# Baixa o GroundingDINO\n",
        "if not os.path.exists(DINO_FILENAME):\n",
        "  print(f\"Baixando {DINO_FILENAME}...\")\n",
        "  !wget {DINO_URL} -O {DINO_FILENAME}\n",
        "else:\n",
        "  print(f\"{DINO_FILENAME} j√° existe. Pulando download.\")\n",
        "\n",
        "# --- 3. Modificar o Arquivo de Configura√ß√£o ---\n",
        "if CKPT_FILENAME and os.path.exists(CONFIG_FILE):\n",
        "  print(f\"Modificando {CONFIG_FILE} para usar {SAM_VERSION}...\")\n",
        "\n",
        "  # Substitui a linha do CHECKPOINT_PATH\n",
        "  !sed -i -E \"s#^(\\s*SAM_CHECKPOINT_PATH\\s*=\\s*).*#\\1'./pretrained_ckpts/{CKPT_FILENAME}'#\" {CONFIG_FILE}\n",
        "\n",
        "  # Substitui a linha do registro do modelo\n",
        "  # <-- CORRE√á√ÉO AQUI: Removida a aspa simples extra ANTES de \\2\n",
        "  !sed -i -E \"s#^(\\s*sam\\s*=\\s*sam_hq_model_registry\\['vit_).('\\]\\(.*$)#\\1{MODEL_KEY}\\2#\" {CONFIG_FILE}\n",
        "\n",
        "  print(\"Modifica√ß√£o conclu√≠da. Verifica√ß√£o:\")\n",
        "  !grep \"SAM_CHECKPOINT_PATH\" {CONFIG_FILE}\n",
        "  !grep \"sam_hq_model_registry\" {CONFIG_FILE}\n",
        "\n",
        "elif not os.path.exists(CONFIG_FILE):\n",
        "  print(f\"ERRO: Arquivo de configura√ß√£o n√£o encontrado em {CONFIG_FILE}\")\n",
        "else:\n",
        "  print(\"Arquivo de configura√ß√£o n√£o modificado.\")\n",
        "\n",
        "# Volta para o diret√≥rio /content por seguran√ßa\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "wA6atqzdmzH4",
        "outputId": "44bad76f-adbf-477e-e914-572782b77a66"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UniVAD/pretrained_ckpts\n",
            "Baixando sam_vit_b.pth...\n",
            "--2025-11-09 12:48:55--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.14, 3.163.189.51, 3.163.189.96, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 375042383 (358M) [binary/octet-stream]\n",
            "Saving to: ‚Äòsam_vit_b.pth‚Äô\n",
            "\n",
            "sam_vit_b.pth       100%[===================>] 357.67M   328MB/s    in 1.1s    \n",
            "\n",
            "2025-11-09 12:48:56 (328 MB/s) - ‚Äòsam_vit_b.pth‚Äô saved [375042383/375042383]\n",
            "\n",
            "Baixando groundingdino_swint_ogc.pth...\n",
            "--2025-11-09 12:48:56--  https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha/groundingdino_swint_ogc.pth\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/611591640/f221e500-c2fc-4fd3-b84e-8ad92a6923f3?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-09T13%3A26%3A10Z&rscd=attachment%3B+filename%3Dgroundingdino_swint_ogc.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-09T12%3A26%3A01Z&ske=2025-11-09T13%3A26%3A10Z&sks=b&skv=2018-11-09&sig=gE%2FNJKmhbZ6UGZ5EfYi8uG0wMlDC3dwQtdPm5tBaIAI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MjY5NjEzNywibmJmIjoxNzYyNjkyNTM3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.dG58DVstgdBUBD9WPB6mY_OWVs2_sZ2ManVuQxkZ6z0&response-content-disposition=attachment%3B%20filename%3Dgroundingdino_swint_ogc.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-11-09 12:48:57--  https://release-assets.githubusercontent.com/github-production-release-asset/611591640/f221e500-c2fc-4fd3-b84e-8ad92a6923f3?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-11-09T13%3A26%3A10Z&rscd=attachment%3B+filename%3Dgroundingdino_swint_ogc.pth&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-11-09T12%3A26%3A01Z&ske=2025-11-09T13%3A26%3A10Z&sks=b&skv=2018-11-09&sig=gE%2FNJKmhbZ6UGZ5EfYi8uG0wMlDC3dwQtdPm5tBaIAI%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2MjY5NjEzNywibmJmIjoxNzYyNjkyNTM3LCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.dG58DVstgdBUBD9WPB6mY_OWVs2_sZ2ManVuQxkZ6z0&response-content-disposition=attachment%3B%20filename%3Dgroundingdino_swint_ogc.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 693997677 (662M) [application/octet-stream]\n",
            "Saving to: ‚Äògroundingdino_swint_ogc.pth‚Äô\n",
            "\n",
            "groundingdino_swint 100%[===================>] 661.85M   124MB/s    in 5.5s    \n",
            "\n",
            "2025-11-09 12:49:02 (120 MB/s) - ‚Äògroundingdino_swint_ogc.pth‚Äô saved [693997677/693997677]\n",
            "\n",
            "Modificando /content/UniVAD/models/component_segmentaion.py para usar SAM-B...\n",
            "Modifica√ß√£o conclu√≠da. Verifica√ß√£o:\n",
            "        SAM_CHECKPOINT_PATH = './pretrained_ckpts/sam_vit_b.pth'\n",
            "        for path in [GROUNDING_DINO_CONFIG_PATH, GROUNDING_DINO_CHECKPOINT_PATH, SAM_CHECKPOINT_PATH]:\n",
            "        sam = sam_hq_model_registry['vit_b'](SAM_CHECKPOINT_PATH).to(self.device)\n",
            "    sam_hq_model_registry,\n",
            "        sam = sam_hq_model_registry['vit_b'](SAM_CHECKPOINT_PATH).to(self.device)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Vdj628Bq3V_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45579950-2608-4fa0-9a7c-30b6d0d25556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/UniVAD\n"
          ]
        }
      ],
      "source": [
        "%cd /content/UniVAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ory58_-F3hZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "673ff4dd-8218-47cf-9e20-1168491a92f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (75.2.0)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.2.0\n",
            "    Uninstalling setuptools-75.2.0:\n",
            "      Successfully uninstalled setuptools-75.2.0\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-25.3 setuptools-80.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack"
                ]
              },
              "id": "6542aca9ffe340918a800552ee264191"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Para usar segment_components.py\n",
        "\n",
        "!pip install --upgrade pip setuptools wheel\n",
        "\n",
        "# For√ßar vers√£o do transformers compat√≠vel\n",
        "!pip install transformers==4.44.2 --upgrade --quiet\n",
        "\n",
        "# Instala tokenizers que tem wheel para Python 3.12\n",
        "!pip install tokenizers==0.19.1 --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import re\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==============================================================================\n",
        "# ======================== PAINEL DE CONTROLE DO DATASET =======================\n",
        "# ==============================================================================\n",
        "# Altere apenas os par√¢metros nesta se√ß√£o para configurar seu dataset.\n",
        "\n",
        "# --- 1. Sele√ß√£o da C√¢mera ---\n",
        "# Escolha de qual c√¢mera processar as imagens.\n",
        "# Op√ß√µes: 'cam1', 'cam2', 'both'\n",
        "SELECT_CAMERA = 'cam1'\n",
        "\n",
        "# --- 2. Defini√ß√£o das Amostras \"Boas\" (Normais) ---\n",
        "# Coloque aqui os N√öMEROS das caixas que s√£o consideradas \"boas\".\n",
        "# Qualquer caixa com um n√∫mero fora desta lista ser√° considerada \"ruim\" (an√¥mala).\n",
        "GOOD_BOX_NUMBERS = {14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 32, 33}\n",
        "\n",
        "# --- 3. Sele√ß√£o das Amostras de TREINO ---\n",
        "# Todas as imagens de treino devem pertencer √†s classes \"boas\".\n",
        "# O script ir√° verificar isso e emitir um aviso se voc√™ tentar usar uma amostra \"ruim\" para treino.\n",
        "\n",
        "# Abordagem A: Por N√öMERO da caixa.\n",
        "# Todas as imagens das caixas com estes n√∫meros ser√£o movidas para 'train/good'.\n",
        "# TRAIN_BOX_NUMBERS = {15, 19}\n",
        "TRAIN_BOX_NUMBERS = {}\n",
        "\n",
        "# Abordagem B: Por NOME DE ARQUIVO espec√≠fico.\n",
        "# √ötil para selecionar manualmente algumas imagens de caixas que tamb√©m ir√£o para teste.\n",
        "# INCLUA O PREFIXO DA C√ÇMERA (cam1_ ou cam2_) no nome do arquivo. ---\n",
        "# IMPORTANTE: Use o formato do nome com underscores '_', n√£o pontos '.'.\n",
        "TRAIN_SPECIFIC_FILENAMES = {\n",
        "    'cam1_board15_1_b.jpg',\n",
        "    # 'cam1_board16_4_2.jpg',\n",
        "    # 'cam1_board17_2_1.jpg',\n",
        "    # 'cam1_board18_3_2.jpg',\n",
        "    # 'cam1_board15_1_b.jpg',\n",
        "    # 'cam1_board16_3_b.jpg',\n",
        "    # 'cam1_board19_2_b.jpg'\n",
        "    # Exemplo para C√¢mera 2: 'cam2_board19_2.jpg',\n",
        "    # Adicione outros nomes de arquivo espec√≠ficos aqui se desejar.\n",
        "}\n",
        "\n",
        "# TRAIN_SPECIFIC_FILENAMES = {\n",
        "#     'cam1_board15_1_b.jpg',\n",
        "#     'cam1_board16_3_b.jpg',\n",
        "#     'cam1_board19_2_b.jpg'\n",
        "#     # Exemplo para C√¢mera 2: 'cam2_board19_2.jpg',\n",
        "#     # Adicione outros nomes de arquivo espec√≠ficos aqui se desejar.\n",
        "# }\n",
        "\n",
        "# --- 4. Filtro de Localiza√ß√£o da C√¢mera ---\n",
        "# Escolha quais tipos de imagem incluir no dataset.\n",
        "# Op√ß√µes dispon√≠veis: 'chao', 'esteira1', 'esteira2'.\n",
        "# Voc√™ pode incluir uma, duas ou todas as tr√™s.\n",
        "INCLUDE_LOCATIONS = {'esteira1', 'esteira2'}\n",
        "#INCLUDE_LOCATIONS = {'chao'}\n",
        "\n",
        "# --- 5. Exclus√£o de Amostras ---\n",
        "# Coloque aqui os N√öMEROS das caixas que voc√™ quer IGNORAR completamente.\n",
        "# Elas n√£o ser√£o inclu√≠das nem no treino, nem no teste.\n",
        "EXCLUDE_BOX_NUMBERS = {\n",
        "    9, 10, 11\n",
        "}\n",
        "\n",
        "# --- 6. Caminhos de Origem e Destino ---\n",
        "# Caminho da pasta no seu Google Drive com as imagens originais.\n",
        "# ESTA VARI√ÅVEL SER√Å AJUSTADA AUTOMATICAMENTE PELA SELE√á√ÉO DA C√ÇMERA.\n",
        "SOURCE_DIR_CAM1 = '/content/drive/MyDrive/TCC_Dataset/C√¢mera1'\n",
        "SOURCE_DIR_CAM2 = '/content/drive/MyDrive/TCC_Dataset/C√¢mera2'\n",
        "\n",
        "# Caminho base de destino no Colab para o dataset estruturado.\n",
        "DEST_BASE_DIR = '/content/UniVAD/data/CardboardBox'\n",
        "\n",
        "# ==============================================================================\n",
        "# ======================== FIM DO PAINEL DE CONTROLE ===========================\n",
        "# ==============================================================================\n",
        "\n",
        "\n",
        "# --- L√≥gica do Script (n√£o precisa alterar daqui para baixo) ---\n",
        "\n",
        "def get_location(filename: str) -> str:\n",
        "    \"\"\"Identifica a localiza√ß√£o da imagem com base no nome do arquivo.\"\"\"\n",
        "    fn_lower = filename.lower()\n",
        "    if '.b2.jpg' in fn_lower: # Mais robusto que endswith\n",
        "        return 'esteira2'\n",
        "    elif '.b.jpg' in fn_lower: # Mais robusto que endswith\n",
        "        return 'esteira1'\n",
        "    else:\n",
        "        return 'chao'\n",
        "\n",
        "print(\"Montando Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- L√≥gica para selecionar o diret√≥rio de origem ---\n",
        "source_dirs_to_process = []\n",
        "if SELECT_CAMERA == 'cam1':\n",
        "    source_dirs_to_process.append((SOURCE_DIR_CAM1, 'cam1'))\n",
        "elif SELECT_CAMERA == 'cam2':\n",
        "    source_dirs_to_process.append((SOURCE_DIR_CAM2, 'cam2'))\n",
        "elif SELECT_CAMERA == 'both':\n",
        "    source_dirs_to_process.append((SOURCE_DIR_CAM1, 'cam1'))\n",
        "    source_dirs_to_process.append((SOURCE_DIR_CAM2, 'cam2'))\n",
        "else:\n",
        "    raise ValueError(\"SELECT_CAMERA deve ser 'cam1', 'cam2' ou 'both'.\")\n",
        "\n",
        "# --- Prepara√ß√£o de Pastas ---\n",
        "dest_class_dir = os.path.join(DEST_BASE_DIR, 'cardboard_box')\n",
        "train_good_dir = os.path.join(dest_class_dir, 'train', 'good')\n",
        "test_good_dir = os.path.join(dest_class_dir, 'test', 'good')\n",
        "test_bad_dir = os.path.join(dest_class_dir, 'test', 'bad')\n",
        "\n",
        "if os.path.exists(dest_class_dir):\n",
        "    print(f\"Limpando diret√≥rio de destino antigo: {dest_class_dir}\")\n",
        "    shutil.rmtree(dest_class_dir)\n",
        "\n",
        "print(\"Criando nova estrutura de pastas de destino...\")\n",
        "os.makedirs(train_good_dir, exist_ok=True)\n",
        "os.makedirs(test_good_dir, exist_ok=True)\n",
        "os.makedirs(test_bad_dir, exist_ok=True)\n",
        "\n",
        "# Regex para extrair o n√∫mero principal da caixa (ex: 'board14' -> 14)\n",
        "filename_pattern = re.compile(r'board(\\d+)', re.IGNORECASE)\n",
        "\n",
        "# --- Contadores para o Relat√≥rio Final ---\n",
        "counters = {\n",
        "    'train_good': 0, 'test_good': 0, 'test_bad': 0,\n",
        "    'skipped_excluded': 0, 'skipped_location': 0,\n",
        "    'skipped_pattern': 0, 'skipped_other': 0,\n",
        "    'warn_bad_in_train': 0\n",
        "}\n",
        "total_files_in_sources = 0\n",
        "\n",
        "print(\"\\nIniciando a organiza√ß√£o do dataset...\")\n",
        "for source_dir, camera_prefix in source_dirs_to_process:\n",
        "    print(f\"\\nProcessando diret√≥rio: {source_dir} (prefixo: '{camera_prefix}')\")\n",
        "    if not os.path.exists(source_dir):\n",
        "        print(f\"AVISO: Diret√≥rio de origem n√£o encontrado: {source_dir}. Pulando.\")\n",
        "        continue\n",
        "\n",
        "    source_files = os.listdir(source_dir)\n",
        "    total_files_in_sources += len(source_files)\n",
        "\n",
        "    for filename in tqdm(source_files, desc=f\"Processando {camera_prefix}\"):\n",
        "        if not filename.lower().endswith(('.jpg', '.jpeg')):\n",
        "            counters['skipped_other'] += 1\n",
        "            continue\n",
        "\n",
        "        source_path = os.path.join(source_dir, filename)\n",
        "        match = filename_pattern.match(filename)\n",
        "\n",
        "        if not match:\n",
        "            counters['skipped_pattern'] += 1\n",
        "            continue\n",
        "\n",
        "        sample_num = int(match.group(1))\n",
        "\n",
        "        # 1. FILTRO DE EXCLUS√ÉO\n",
        "        if sample_num in EXCLUDE_BOX_NUMBERS:\n",
        "            counters['skipped_excluded'] += 1\n",
        "            continue\n",
        "\n",
        "        # --- Corre√ß√£o da ordem do nome do arquivo para C√¢mera 2 ---\n",
        "        corrected_filename = filename\n",
        "        if camera_prefix == 'cam2':\n",
        "            match_fix = re.match(r'(.*)\\.(b2?)\\.(\\d+)\\.jpg', filename, re.IGNORECASE)\n",
        "            if match_fix:\n",
        "                base, esteira_id, num = match_fix.groups()\n",
        "                corrected_filename = f\"{base}.{num}.{esteira_id}.jpg\"\n",
        "\n",
        "        # 2. FILTRO DE LOCALIZA√á√ÉO (usa o nome corrigido para consist√™ncia)\n",
        "        location = get_location(corrected_filename)\n",
        "        if location not in INCLUDE_LOCATIONS:\n",
        "            counters['skipped_location'] += 1\n",
        "            continue\n",
        "\n",
        "        # --- Renomeia o arquivo (troca '.' por '_') e adiciona prefixo ---\n",
        "        base_name, extension = os.path.splitext(corrected_filename)\n",
        "        new_base_name = base_name.replace('.', '_')\n",
        "        new_filename_with_prefix = f\"{camera_prefix}_{new_base_name}{extension}\"\n",
        "\n",
        "        # 3. CLASSIFICA√á√ÉO (GOOD vs BAD)\n",
        "        is_good_class = sample_num in GOOD_BOX_NUMBERS\n",
        "\n",
        "        # 4. DIVIS√ÉO (TRAIN vs TEST)\n",
        "        # --- NOVA ALTERA√á√ÉO: Verifica o nome COM prefixo na lista de treino ---\n",
        "        is_for_training = (sample_num in TRAIN_BOX_NUMBERS) or (new_filename_with_prefix in TRAIN_SPECIFIC_FILENAMES)\n",
        "\n",
        "        dest_sub_dir = None\n",
        "        if is_for_training:\n",
        "            if is_good_class:\n",
        "                dest_sub_dir = train_good_dir\n",
        "                counters['train_good'] += 1\n",
        "            else:\n",
        "                print(f\"AVISO: Tentativa de adicionar amostra 'bad' ({filename}) ao conjunto de treino. Pulando.\")\n",
        "                counters['warn_bad_in_train'] += 1\n",
        "                continue\n",
        "        else:\n",
        "            if is_good_class:\n",
        "                dest_sub_dir = test_good_dir\n",
        "                counters['test_good'] += 1\n",
        "            else:\n",
        "                dest_sub_dir = test_bad_dir\n",
        "                counters['test_bad'] += 1\n",
        "\n",
        "        # Copia o arquivo para o destino correto\n",
        "        dest_path = os.path.join(dest_sub_dir, new_filename_with_prefix)\n",
        "        try:\n",
        "            shutil.copy2(source_path, dest_path)\n",
        "        except Exception as e:\n",
        "            print(f\"ERRO ao copiar {filename}: {e}\")\n",
        "            if dest_sub_dir == train_good_dir: counters['train_good'] -= 1\n",
        "            elif dest_sub_dir == test_good_dir: counters['test_good'] -= 1\n",
        "            elif dest_sub_dir == test_bad_dir: counters['test_bad'] -= 1\n",
        "            counters['skipped_other'] += 1\n",
        "\n",
        "# --- Relat√≥rio Final ---\n",
        "total_copied = counters['train_good'] + counters['test_good'] + counters['test_bad']\n",
        "total_skipped = total_files_in_sources - total_copied - counters['warn_bad_in_train']\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Organiza√ß√£o Conclu√≠da!\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\n--- Resumo da Gera√ß√£o do Dataset ---\")\n",
        "print(f\"Imagens copiadas para 'train/good': {counters['train_good']}\")\n",
        "print(f\"Imagens copiadas para 'test/good':  {counters['test_good']}\")\n",
        "print(f\"Imagens copiadas para 'test/bad':   {counters['test_bad']}\")\n",
        "print(f\"-------------------------------------------\")\n",
        "print(f\"Total de imagens no novo dataset: {total_copied}\")\n",
        "\n",
        "print(\"\\n--- Resumo das Imagens Ignoradas ---\")\n",
        "print(f\"Puladas por estarem na lista de exclus√£o: {counters['skipped_excluded']}\")\n",
        "print(f\"Puladas por filtro de localiza√ß√£o:        {counters['skipped_location']}\")\n",
        "print(f\"Puladas por n√£o corresponder ao padr√£o:   {counters['skipped_pattern']}\")\n",
        "print(f\"Avisos de amostras 'bad' em treino:       {counters['warn_bad_in_train']}\")\n",
        "print(f\"Outros arquivos ignorados (n√£o-jpg):    {counters['skipped_other']}\")\n",
        "print(f\"-------------------------------------------\")\n",
        "print(f\"Total de arquivos ignorados: {total_skipped + counters['warn_bad_in_train']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"Total de arquivos nos diret√≥rios de origem: {total_files_in_sources}\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0XOLQcyGd9q",
        "outputId": "bb1ab225-cf46-4a70-fb1e-d02c27b402ac"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Montando Google Drive...\n",
            "Mounted at /content/drive\n",
            "Criando nova estrutura de pastas de destino...\n",
            "\n",
            "Iniciando a organiza√ß√£o do dataset...\n",
            "\n",
            "Processando diret√≥rio: /content/drive/MyDrive/TCC_Dataset/C√¢mera1 (prefixo: 'cam1')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processando cam1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 282/282 [00:13<00:00, 20.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Organiza√ß√£o Conclu√≠da!\n",
            "==================================================\n",
            "\n",
            "--- Resumo da Gera√ß√£o do Dataset ---\n",
            "Imagens copiadas para 'train/good': 1\n",
            "Imagens copiadas para 'test/good':  35\n",
            "Imagens copiadas para 'test/bad':   90\n",
            "-------------------------------------------\n",
            "Total de imagens no novo dataset: 126\n",
            "\n",
            "--- Resumo das Imagens Ignoradas ---\n",
            "Puladas por estarem na lista de exclus√£o: 21\n",
            "Puladas por filtro de localiza√ß√£o:        132\n",
            "Puladas por n√£o corresponder ao padr√£o:   0\n",
            "Avisos de amostras 'bad' em treino:       0\n",
            "Outros arquivos ignorados (n√£o-jpg):    3\n",
            "-------------------------------------------\n",
            "Total de arquivos ignorados: 156\n",
            "\n",
            "==================================================\n",
            "Total de arquivos nos diret√≥rios de origem: 282\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_univad.py --dataset cardboard_box --data_path ./data/CardboardBox --k_shot 1 --round 0 --image_size 224 --anomaly_threshold 0.6 --class_name cardboard_box --debug"
      ],
      "metadata": {
        "id": "VZrnMwSy0yx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar um .zip da pasta de resultados\n",
        "!zip -r /content/results.zip /content/UniVAD/results"
      ],
      "metadata": {
        "id": "nsTCDAUAJrLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvar um .zip da pasta de m√°scaras\n",
        "!zip -r /content/results.zip /content/UniVAD/masks"
      ],
      "metadata": {
        "id": "5ofHUPMdKJdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1JE-9Gt8OhQ"
      },
      "outputs": [],
      "source": [
        "# Limpar as pastas de testes anteriores\n",
        "\n",
        "! rm -rf /content/UniVAD/results\n",
        "! rm -rf /content/UniVAD/masks\n",
        "! rm -rf /content/UniVAD/heat_masks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_single_inference.py \\\n",
        "    --image_path \"./data/CardboardBox/cardboard_box/test/bad/cam1_board12_1_b.jpg\" \\\n",
        "    --reference_dir \"./data/CardboardBox/cardboard_box/train/good\" \\\n",
        "    --class_name \"cardboard_box\" \\\n",
        "    --data_path \"./data/CardboardBox\" \\\n",
        "    --anomaly_threshold 0.6 \\\n",
        "    --filter_with_mask \\\n",
        "    --debug"
      ],
      "metadata": {
        "id": "hMsbEVSDgnFM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}